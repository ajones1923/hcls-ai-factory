# ================================================================
# HCLS AI Factory - Environment Configuration
# ================================================================
# Copy this file to .env and fill in your values:
#   cp .env.example .env
#
# NEVER commit the .env file - it's gitignored for your protection
# ================================================================

# ================================================================
# NVIDIA NGC (Required for Parabricks and BioNeMo)
# ================================================================
# Get your API key: https://ngc.nvidia.com/setup/api-key
NGC_API_KEY=your-ngc-api-key-here

# ================================================================
# Anthropic (Required for RAG/Chat pipeline)
# ================================================================
# Get your API key: https://console.anthropic.com/
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# ================================================================
# HuggingFace (Optional - for local LLM models)
# ================================================================
# Get your token: https://huggingface.co/settings/tokens
HF_TOKEN=your-huggingface-token-here

# ================================================================
# LLM Configuration
# ================================================================
# Provider: anthropic, ollama, openai, vllm
# Default in code is ollama (local LLM for ARM64/DGX Spark).
# Set to anthropic if using Claude API.
LLM_PROVIDER=anthropic
LLM_MODEL=claude-sonnet-4-20250514

# For local LLM on DGX Spark (default if LLM_PROVIDER not set):
# LLM_PROVIDER=ollama
# LLM_MODEL=llama3.1:70b
# OLLAMA_HOST=http://localhost:11434

# For vLLM on x86 systems:
# LLM_PROVIDER=vllm
# VLLM_HOST=localhost
# VLLM_PORT=8080
# VLLM_MODEL=meta-llama/Llama-3.1-70B-Instruct

# ================================================================
# Milvus Vector Database
# ================================================================
MILVUS_HOST=localhost
MILVUS_PORT=19530

# ================================================================
# BioNeMo Services
# ================================================================
MOLMIM_URL=http://localhost:8001
DIFFDOCK_URL=http://localhost:8002
# Set to true to use mock NIM services for demo without GPU
# NIM_ALLOW_MOCK_FALLBACK=true

# ================================================================
# RAG Settings
# ================================================================
RAG_TOP_K=10
RAG_SCORE_THRESHOLD=0.5
LLM_MAX_TOKENS=2048
LLM_TEMPERATURE=0.7

# ================================================================
# Monitoring (Optional)
# ================================================================
GRAFANA_USER=admin
GRAFANA_PASSWORD=change-this-password

# ================================================================
# Data Paths
# ================================================================
VCF_INPUT_PATH=/path/to/your/variants.vcf.gz
