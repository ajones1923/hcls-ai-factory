# RAG Chat Pipeline Environment Configuration
# Copy this to .env and configure for your setup

# ============================================
# LOCAL LLM CONFIGURATION (Default)
# ============================================

# Hugging Face token (required for gated models like Llama)
# Get yours at: https://huggingface.co/settings/tokens
HF_TOKEN=your_huggingface_token_here

# Model selection - choose based on your GPU VRAM:
#
# | Model                                    | VRAM   | Quality    |
# |------------------------------------------|--------|------------|
# | meta-llama/Llama-3.1-70B-Instruct        | 80GB+  | Excellent  | <- DGX Spark
# | meta-llama/Llama-3.3-70B-Instruct        | 80GB+  | Latest     | <- DGX Spark
# | Qwen/Qwen2.5-72B-Instruct                | 80GB+  | Excellent  | <- DGX Spark
# | meta-llama/Llama-3.1-8B-Instruct         | 16GB+  | Good       |
# | BioMistral/BioMistral-7B                 | 14GB+  | Biomedical |
#
# DGX Spark (128GB) - Use 70B models for best quality
VLLM_MODEL=meta-llama/Llama-3.1-70B-Instruct

# LLM Provider (vllm = local, anthropic/openai = cloud)
LLM_PROVIDER=vllm

# ============================================
# CLOUD API (Alternative - uncomment to use)
# ============================================

# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# LLM_PROVIDER=anthropic
# LLM_MODEL=claude-sonnet-4-20250514

# OPENAI_API_KEY=your_openai_api_key_here
# LLM_PROVIDER=openai
# LLM_MODEL=gpt-4-turbo-preview

# ============================================
# MILVUS CONFIGURATION
# ============================================

MILVUS_HOST=localhost
MILVUS_PORT=19530

# ============================================
# VCF INPUT PATH
# ============================================

# Path to VCF file from genomics-pipeline
# Default uses sibling genomics-pipeline directory: ../genomics-pipeline/data/output/HG002.genome.vcf.gz
# Uncomment and set to override:
# VCF_INPUT_PATH=/path/to/your/variants.vcf.gz

# ============================================
# RAG SETTINGS
# ============================================

RAG_TOP_K=10
RAG_SCORE_THRESHOLD=0.5
LLM_MAX_TOKENS=2048
LLM_TEMPERATURE=0.7
